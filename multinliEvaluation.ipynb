{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import argparse\n",
    "import sys, os\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "\n",
    "from data import get_nli, get_batch, build_vocab\n",
    "from mutils import get_optimizer, dotdict\n",
    "from models import NLINet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_multinli(data_path):\n",
    "    s1 = {}\n",
    "    s2 = {}\n",
    "    target = {}\n",
    "    \n",
    "    dico_label = {'entailment':0,  'neutral':1, 'contradiction':2}\n",
    "    \n",
    "    for data_type in ['train', 'dev', 'test']:\n",
    "        s1[data_type], s2[data_type], target[data_type] = {}, {}, {}\n",
    "        s1[data_type]['path'] = os.path.join(data_path, 's1.' + data_type)\n",
    "        s2[data_type]['path'] = os.path.join(data_path, 's2.' + data_type)\n",
    "        target[data_type]['path'] = os.path.join(data_path, 'labels.' + data_type)\n",
    "        \n",
    "        s1[data_type]['sent'] = [line.rstrip() for line in open(s1[data_type]['path'], 'r')]\n",
    "        s2[data_type]['sent'] = [line.rstrip() for line in open(s2[data_type]['path'], 'r')]\n",
    "        target[data_type]['data'] = np.array([dico_label[line.rstrip('\\n')] for line in open(target[data_type]['path'], 'r')])\n",
    "        \n",
    "        assert len(s1[data_type]['sent']) == len(s2[data_type]['sent']) == len(target[data_type]['data'])\n",
    "        \n",
    "        print('** {0} DATA : Found {1} pairs of {2} sentences.'.format(\n",
    "                            data_type.upper(), len(s1[data_type]['sent']), data_type))\n",
    "        \n",
    "        \n",
    "    train = {'s1':s1['train']['sent'], 's2':s2['train']['sent'], 'label':target['train']['data']}\n",
    "    dev = {'s1':s1['dev']['sent'], 's2':s2['dev']['sent'], 'label':target['dev']['data']}\n",
    "    test  = {'s1':s1['test']['sent'] , 's2':s2['test']['sent'] , 'label':target['test']['data'] }\n",
    "    return train, dev, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev.matched.multinli.txt          s1.train\r\n",
      "dev.matched.multinli.txt.tok      s2.dev.matched\r\n",
      "dev.mismatched.multinli.txt       s2.dev.mismatched\r\n",
      "dev.mismatched.multinli.txt.tok   s2.test.matched.unlabeled\r\n",
      "labels.dev.matched                s2.test.mismatched.unlabeled\r\n",
      "labels.dev.mismatched             s2.train\r\n",
      "labels.test.matched.unlabeled     test.matched.unlabeled.multinli.txt\r\n",
      "labels.test.mismatched.unlabeled  test.matched.unlabeled.multinli.txt.tok\r\n",
      "labels.train                      test.mismatched.unlabeled.multinli.txt\r\n",
      "s1.dev.matched                    test.mismatched.unlabeled.multinli.txt.tok\r\n",
      "s1.dev.mismatched                 train.multinli.txt\r\n",
      "s1.test.matched.unlabeled         train.multinli.txt.tok\r\n",
      "s1.test.mismatched.unlabeled\r\n"
     ]
    }
   ],
   "source": [
    "ls dataset3/MultiNLI_2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Icon                               multinli_0.9_dev_mismatched.txt\r\n",
      "multinli_0.9_dev_matched.jsonl     multinli_0.9_train.jsonl\r\n",
      "multinli_0.9_dev_matched.txt       multinli_0.9_train.txt\r\n",
      "multinli_0.9_dev_mismatched.jsonl  paper.pdf\r\n"
     ]
    }
   ],
   "source": [
    "ls dataset2/MultiNLI/multinli_0.9/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "GLOVE_PATH = \"dataset/GloVe/glove.840B.300d.txt\"\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='NLI training')\n",
    "# paths\n",
    "parser.add_argument(\"--nlipath\", type=str, default='dataset/SNLI/', help=\"NLI data path (SNLI or MultiNLI)\")\n",
    "parser.add_argument(\"--outputdir\", type=str, default='savedir2/', help=\"Output directory\")\n",
    "parser.add_argument(\"--outputmodelname\", type=str, default='model.pickle')\n",
    "\n",
    "\n",
    "# training\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=20)\n",
    "parser.add_argument(\"--batch_size\", type=int, default=64)\n",
    "parser.add_argument(\"--dpout_model\", type=float, default=0., help=\"encoder dropout\")\n",
    "parser.add_argument(\"--dpout_fc\", type=float, default=0., help=\"classifier dropout\")\n",
    "parser.add_argument(\"--nonlinear_fc\", type=float, default=0, help=\"use nonlinearity in fc\")\n",
    "parser.add_argument(\"--optimizer\", type=str, default=\"sgd,lr=0.1\", help=\"adam or sgd,lr=0.1\")\n",
    "parser.add_argument(\"--lrshrink\", type=float, default=5, help=\"shrink factor for sgd\")\n",
    "parser.add_argument(\"--decay\", type=float, default=0.99, help=\"lr decay\")\n",
    "parser.add_argument(\"--minlr\", type=float, default=1e-5, help=\"minimum lr\")\n",
    "parser.add_argument(\"--max_norm\", type=float, default=5., help=\"max norm (grad clipping)\")\n",
    "\n",
    "#model\n",
    "parser.add_argument(\"--encoder_type\", type=str, default='BLSTMEncoder', help=\"see list of encoders\")\n",
    "parser.add_argument(\"--enc_lstm_dim\", type=int, default=2048, help=\"encoder nhid dimension\")\n",
    "parser.add_argument(\"--n_enc_layers\", type=int, default=1, help=\"encoder num layers\")\n",
    "parser.add_argument(\"--fc_dim\", type=int, default=512, help=\"nhid of fc layers\")\n",
    "parser.add_argument(\"--n_classes\", type=int, default=3, help=\"entailment/neutral/contradiction\")\n",
    "parser.add_argument(\"--pool_type\", type=str, default='max', help=\"max or mean\")\n",
    "\n",
    "# gpu\n",
    "parser.add_argument(\"--gpu_id\", type=int, default=0, help=\"GPU ID\")\n",
    "parser.add_argument(\"--seed\", type=int, default=1234, help=\"seed\")\n",
    "\n",
    "\n",
    "params, _ = parser.parse_known_args(\" \".split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** TRAIN DATA : Found 549367 pairs of train sentences.\n",
      "** DEV DATA : Found 9842 pairs of dev sentences.\n",
      "** TEST DATA : Found 9824 pairs of test sentences.\n"
     ]
    }
   ],
   "source": [
    "train, valid, test = get_nli(params.nlipath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train['s1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=64, decay=0.99, dpout_fc=0.0, dpout_model=0.0, enc_lstm_dim=2048, encoder_type='BLSTMEncoder', fc_dim=512, gpu_id=0, lrshrink=5, max_norm=5.0, minlr=1e-05, n_classes=3, n_enc_layers=1, n_epochs=20, nlipath='dataset/SNLI/', nonlinear_fc=0, optimizer='sgd,lr=0.1', outputdir='savedir2/', outputmodelname='model.pickle', pool_type='max', seed=1234)\n",
      "** TRAIN DATA : Found 549367 pairs of train sentences.\n",
      "** DEV DATA : Found 9842 pairs of dev sentences.\n",
      "** TEST DATA : Found 9824 pairs of test sentences.\n",
      "Found 38957(/43479) words with glove vectors\n",
      "Vocab size : 38957\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# set gpu device\n",
    "torch.cuda.set_device(params.gpu_id)\n",
    "\n",
    "# print parameters passed, and all parameters\n",
    "# print('\\ntogrep : {0}\\n'.format(sys.argv[1:]))\n",
    "print(params)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "SEED\n",
    "\"\"\"\n",
    "np.random.seed(params.seed)\n",
    "torch.manual_seed(params.seed)\n",
    "torch.cuda.manual_seed(params.seed)\n",
    "\n",
    "\"\"\"\n",
    "DATA\n",
    "\"\"\"\n",
    "train, valid, test = get_nli(params.nlipath)\n",
    "word_vec = build_vocab(train['s1'] + train['s2'] + valid['s1'] + valid['s2'] + test['s1'] + test['s2'], GLOVE_PATH)\n",
    "\n",
    "for split in ['s1', 's2']:\n",
    "    for data_type in ['train', 'valid', 'test']:\n",
    "        eval(data_type)[split] = np.array([['<s>'] + [word for word in sent.split() if word in word_vec] +\\\n",
    "                                          ['</s>'] for sent in eval(data_type)[split]])        \n",
    "\n",
    "params.word_emb_dim = 300\n",
    "\n",
    "\n",
    "# \"\"\"\n",
    "# MODEL\n",
    "# \"\"\"\n",
    "# # model config\n",
    "# config_nli_model = {\n",
    "#     'n_words'        :  len(word_vec)          ,\n",
    "#     'word_emb_dim'   :  params.word_emb_dim   ,\n",
    "#     'enc_lstm_dim'   :  params.enc_lstm_dim   ,\n",
    "#     'n_enc_layers'   :  params.n_enc_layers   ,\n",
    "#     'dpout_model'    :  params.dpout_model    ,\n",
    "#     'dpout_fc'       :  params.dpout_fc       ,\n",
    "#     'fc_dim'         :  params.fc_dim         ,\n",
    "#     'bsize'          :  params.batch_size     ,\n",
    "#     'n_classes'      :  params.n_classes      ,\n",
    "#     'pool_type'      :  params.pool_type      ,\n",
    "#     'nonlinear_fc'   :  params.nonlinear_fc   ,\n",
    "#     'encoder_type'   :  params.encoder_type   ,\n",
    "#     'use_cuda'       :  True                  ,\n",
    "\n",
    "# }\n",
    "\n",
    "# # model\n",
    "# encoder_types = ['BLSTMEncoder', 'BLSTMprojEncoder', 'BGRUlastEncoder', 'InnerAttentionMILAEncoder',\\\n",
    "#                  'InnerAttentionYANGEncoder', 'InnerAttentionNAACLEncoder', 'ConvNetEncoder', 'LSTMEncoder']\n",
    "# assert params.encoder_type in encoder_types, \"encoder_type must be in \" + str(encoder_types)\n",
    "# nli_net = NLINet(config_nli_model)\n",
    "# print(nli_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss\n",
    "weight = torch.FloatTensor(params.n_classes).fill_(1)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=weight)\n",
    "loss_fn.size_average = False\n",
    "\n",
    "# optimizer\n",
    "optim_fn, optim_params = get_optimizer(params.optimizer)\n",
    "optimizer = optim_fn(nli_net.parameters(), **optim_params)\n",
    "\n",
    "# cuda by default\n",
    "nli_net.cuda()\n",
    "loss_fn.cuda()\n",
    "#src_embeddings.cuda()\n",
    "\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "TRAIN\n",
    "\"\"\"\n",
    "#src_embeddings.volatile = True\n",
    "val_acc_best = -1e10\n",
    "adam_stop = False\n",
    "stop_training = False\n",
    "lr = optim_params['lr'] if 'sgd' in params.optimizer else None\n",
    "#index_pad =word2id['<p>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ list(['<s>', 'This', 'church', 'choir', 'sings', 'to', 'the', 'masses', 'as', 'they', 'sing', 'joyous', 'songs', 'from', 'the', 'book', 'at', 'a', 'church', '.', '</s>']),\n",
       "       list(['<s>', 'This', 'church', 'choir', 'sings', 'to', 'the', 'masses', 'as', 'they', 'sing', 'joyous', 'songs', 'from', 'the', 'book', 'at', 'a', 'church', '.', '</s>']),\n",
       "       list(['<s>', 'This', 'church', 'choir', 'sings', 'to', 'the', 'masses', 'as', 'they', 'sing', 'joyous', 'songs', 'from', 'the', 'book', 'at', 'a', 'church', '.', '</s>']),\n",
       "       ...,\n",
       "       list(['<s>', 'A', 'man', 'in', 'a', 'black', 'leather', 'jacket', 'and', 'a', 'book', 'in', 'his', 'hand', 'speaks', 'in', 'a', 'classroom', '.', '</s>']),\n",
       "       list(['<s>', 'A', 'man', 'in', 'a', 'black', 'leather', 'jacket', 'and', 'a', 'book', 'in', 'his', 'hand', 'speaks', 'in', 'a', 'classroom', '.', '</s>']),\n",
       "       list(['<s>', 'A', 'man', 'in', 'a', 'black', 'leather', 'jacket', 'and', 'a', 'book', 'in', 'his', 'hand', 'speaks', 'in', 'a', 'classroom', '.', '</s>'])], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['s1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(epoch, eval_type='valid', final_eval=False):\n",
    "    nli_net.eval()\n",
    "    correct = 0.\n",
    "    global val_acc_best, lr, stop_training, adam_stop\n",
    "#     print(\"val acc best, lr, stop_training, adam_stop: \", val_acc_best, lr, stop_training, adam_stop)\n",
    "    if eval_type == 'valid':\n",
    "        print('\\nVALIDATION : Epoch {0}'.format(epoch))\n",
    "    \n",
    "    s1    = valid['s1']    if eval_type == 'valid' else test['s1']\n",
    "    s2    = valid['s2']    if eval_type == 'valid' else test['s2']\n",
    "    target = valid['label'] if eval_type == 'valid' else test['label']\n",
    "\n",
    "    for i in range(0, len(s1), params.batch_size):\n",
    "        # prepare batch\n",
    "        s1_batch, s1_len = get_batch(s1[i:i + params.batch_size], word_vec)\n",
    "        s2_batch, s2_len = get_batch(s2[i:i + params.batch_size], word_vec)\n",
    "        s1_batch, s2_batch = Variable(s1_batch.cuda()), Variable(s2_batch.cuda())\n",
    "        tgt_batch = Variable(torch.LongTensor(target[i:i + params.batch_size])).cuda()\n",
    "        k = s1_batch.size(1)  # actual batch size\n",
    "#         print(\"yo, I am here\")\n",
    "        first_arg = (s1_batch, s1_len)\n",
    "        second_arg = (s2_batch, s2_len)\n",
    "        # model forward\n",
    "        output = nli_net(first_arg, second_arg )\n",
    "        \n",
    "        pred = output.data.max(1)[1]\n",
    "        correct += pred.long().eq(tgt_batch.data.long()).cpu().sum()\n",
    "        print(pred)\n",
    "        \n",
    "    # save model\n",
    "    eval_acc  = round(100 * correct / len(s1),2)\n",
    "    if final_eval:\n",
    "        print('finalgrep : accuracy {0} : {1}'.format(eval_type, eval_acc))\n",
    "    else:\n",
    "        print('togrep : results : epoch {0} ; mean accuracy {1} : {2}'.format(epoch, eval_type, eval_acc))\n",
    "    \n",
    "    if eval_type == 'valid' and epoch <= params.n_epochs:\n",
    "        if eval_acc > val_acc_best:\n",
    "            print('saving model at epoch {0}'.format(epoch))\n",
    "            if not os.path.exists(params.outputdir):\n",
    "                os.makedirs(params.outputdir)\n",
    "            torch.save(nli_net, os.path.join(params.outputdir, params.outputmodelname))\n",
    "            val_acc_best = eval_acc\n",
    "        else:\n",
    "            if 'sgd' in params.optimizer:\n",
    "                optimizer.param_groups[0]['lr'] = optimizer.param_groups[0]['lr'] / params.lrshrink\n",
    "                print('Shrinking lr by : {0}. New lr = {1}'.format(params.lrshrink, optimizer.param_groups[0]['lr']))\n",
    "                if optimizer.param_groups[0]['lr'] < params.minlr:\n",
    "                    stop_training = True\n",
    "            if 'adam' in params.optimizer:\n",
    "                # early stopping (at 2nd decrease in accuracy)\n",
    "                stop_training = adam_stop\n",
    "                adam_stop = True\n",
    "    return eval_acc, s1,s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST : Epoch 1\n",
      "\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n",
      "\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n",
      "\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n",
      "\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n",
      "\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n",
      "\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n",
      "\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n",
      "\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n",
      "\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n",
      "\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n",
      "\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n",
      "\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n",
      "\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n",
      "\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n",
      "\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n",
      "\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n",
      "\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n",
      "\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n",
      "\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n",
      "\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n",
      "\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n",
      "\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n",
      "\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n",
      "\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n",
      "\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n",
      "\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n",
      "\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n",
      "\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    2\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    2\n",
      "    2\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "[torch.cuda.LongTensor of size 64x1 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-e26c584ccd3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nTEST : Epoch {0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# evaluate(1e6, 'valid', True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-515f1a498898>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(epoch, eval_type, final_eval)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0msecond_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms2_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# model forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnli_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond_arg\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-stuff/InferSent/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, s1, s2)\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;31m# s1 : (s1, s1_len)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-stuff/InferSent/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_tuple)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# Un-sort by length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0midx_unsort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_unsort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_unsort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0msent_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_unsort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch = 1\n",
    "# Run best model on test set.\n",
    "del nli_net\n",
    "nli_net = torch.load(os.path.join(params.outputdir, params.outputmodelname))\n",
    "\n",
    "print('\\nTEST : Epoch {0}'.format(epoch))\n",
    "# evaluate(1e6, 'valid', True)\n",
    "_, s1, s2 = evaluate(0, 'test', True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ list(['<s>', 'This', 'church', 'choir', 'sings', 'to', 'the', 'masses', 'as', 'they', 'sing', 'joyous', 'songs', 'from', 'the', 'book', 'at', 'a', 'church', '.', '</s>']),\n",
       "       list(['<s>', 'This', 'church', 'choir', 'sings', 'to', 'the', 'masses', 'as', 'they', 'sing', 'joyous', 'songs', 'from', 'the', 'book', 'at', 'a', 'church', '.', '</s>']),\n",
       "       list(['<s>', 'This', 'church', 'choir', 'sings', 'to', 'the', 'masses', 'as', 'they', 'sing', 'joyous', 'songs', 'from', 'the', 'book', 'at', 'a', 'church', '.', '</s>']),\n",
       "       ...,\n",
       "       list(['<s>', 'A', 'man', 'in', 'a', 'black', 'leather', 'jacket', 'and', 'a', 'book', 'in', 'his', 'hand', 'speaks', 'in', 'a', 'classroom', '.', '</s>']),\n",
       "       list(['<s>', 'A', 'man', 'in', 'a', 'black', 'leather', 'jacket', 'and', 'a', 'book', 'in', 'his', 'hand', 'speaks', 'in', 'a', 'classroom', '.', '</s>']),\n",
       "       list(['<s>', 'A', 'man', 'in', 'a', 'black', 'leather', 'jacket', 'and', 'a', 'book', 'in', 'his', 'hand', 'speaks', 'in', 'a', 'classroom', '.', '</s>'])], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['s1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#continue to generate multinli csvs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
